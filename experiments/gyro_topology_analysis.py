#!/usr/bin/env python3
"""
GyroSI Topology Analysis: Fermion Mass Patterns in Recursive Structural Intelligence

This script conducts comprehensive physics experiments on the GyroSI topology by mapping
fermion mass analysis results to the finite 788,986-state manifold and analyzing the 
resulting spacetime-like behaviors through the lens of Common Governance Model (CGM) 
principles.

EXPERIMENTAL DESIGN:
1. Map fermion observables (e-exponents, 3° clicks, residuals) to 8-bit introns
2. Apply intron sequences to states using the five canonical atlas maps
3. Track helical progression, parity closure, and commutator defects
4. Validate 720° closure cycles and 30-fold phase division patterns
5. Correlate behaviors with CGM stages (CS/UNA/ONA/BU)

USAGE:
    python gyro_topology_analysis.py --experiment all  # Run complete analysis
    python gyro_topology_analysis.py --experiment up   # Test specific sector
"""

import argparse
import logging
import math
import random
from dataclasses import dataclass, field
from pathlib import Path
from typing import Dict, List, Any, Tuple
import sys

import numpy as np

# Add the project root to Python path for imports
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# Import GyroSI components
try:
    from baby.constants.atlas_builder import AtlasPaths
    # GyroLog removed - using direct LI-invariant plane classification
    from baby.kernel import governance
except ImportError as e:
    print(f"Error importing GyroSI components: {e}")
    print("Ensure you're running from the correct directory with baby/ module available")
    print(f"Project root: {project_root}")
    print(f"Python path: {sys.path[:3]}")
    sys.exit(1)

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


@dataclass
class FermionData:
    """Fermion sector observables from CGM mass analysis."""
    sector: str
    e32: float          # e32 exponent
    e21: float          # e21 exponent (primary diagnostic)
    e13: float          # e13 exponent
    clicks_e32: float   # 3° aperture clicks for e32
    clicks_e21: float   # 3° aperture clicks for e21
    residual: float     # 30-fold phase residual
    mass_ratio: float   # Actual m2/m1 ratio
    aperture_impact: float  # Multiplicative impact of aperture


@dataclass
class ExperimentConfig:
    """Configuration for topology experiments."""
    num_steps: int = 6          # Path length (system diameter)
    num_trials: int = 10        # Trials per experiment
    num_perturbations: int = 5   # Perturbation variants per trial
    random_seed: int = 42       # For reproducibility
    
    # Physics thresholds
    closure_threshold: float = 1.0      # Theta threshold for BU closure (relaxed from 0.1)
    clean_residual_threshold: float = 0.1  # Clean 30-fold threshold
    strong_alignment_threshold: float = 0.05  # Strong pattern threshold


@dataclass
class TopologyExperiment:
    """Single topology experiment tracking state evolution."""
    sector: str
    trial_id: int
    fermion_data: FermionData
    config: ExperimentConfig
    
    # State evolution tracking
    path: List[Dict[str, Any]] = field(default_factory=list)
    intron_sequence: List[int | None] = field(default_factory=list)
    
    # Metrics
    metrics: Dict[str, Any] = field(default_factory=dict)


class FermionToIntronMapper:
    """Maps fermion observables to 8-bit GyroSI introns."""
    
    def __init__(self):
        """Initialize with family bit patterns."""
        # Bit families from governance
        self.LI_BITS = 0b01000010  # Bits 1,6 - chirality/parity
        self.FG_BITS = 0b00100100  # Bits 2,5 - foreground flips  
        self.BG_BITS = 0b00011000  # Bits 3,4 - background interleaving
        self.L0_BITS = 0b10000001  # Bits 0,7 - anchors
        
    def map_fermion_to_intron(self, fermion_data: FermionData, perturbation_seed: int = 0) -> int:
        """
        Map fermion observables to 8-bit intron respecting bit family structure.
        
        For aperture-only experiments, only FG/BG bits are used based on clicks_e21.
        L0 and LI bits are disabled to avoid contamination.
        
        Args:
            fermion_data: Fermion sector data
            perturbation_seed: For trial variations (unused in deterministic mode)
            
        Returns:
            8-bit intron value
        """
        # Aperture-only experiment: only FG/BG bits, no L0 or LI
        # The actual intron sequence is generated by generate_intron_sequence()
        # This method is kept for interface compatibility
        return 0x00
    
    def generate_intron_sequence(
        self, 
        fermion_data: FermionData, 
        length: int,
        perturbation_seed: int = 0
    ) -> List[int | None]:
        """
        Generate intron sequence using best micro-step from validation.
        
        Uses exact enumeration to find the smallest nonzero click sequence,
        then repeats it to achieve the target click count.
        
        Args:
            fermion_data: Fermion sector data
            length: Sequence length
            perturbation_seed: For variations (unused in deterministic mode)
            
        Returns:
            List of introns (or None for no-op padding)
        """
        # Use exact click values from validation (FG1 = 0x04)
        # These are calculated exactly from archetype using atlas
        exact_clicks_per_step = 0.5  # FG1 exact value from archetype
        
        # Calculate total clicks needed
        total_clicks = abs(fermion_data.clicks_e21)
        
        # Calculate number of micro-steps needed
        num_steps = int(round(total_clicks / exact_clicks_per_step))
        
        # Generate sequence using calibrated micro-step
        if num_steps == 0:
            # No clicks - all None (true no-op)
            return [None] * length
        else:
            # Use FG1 micro-step (0x04) for calibrated clicks
            # Distribute steps evenly across the sequence length
            if num_steps >= length:
                # More steps than length - use FG1 for all steps
                return [0x04] * length
            else:
                # Distribute steps evenly, pad with None
                sequence: List[int | None] = [None] * length
                step_interval = length / num_steps
                for i in range(num_steps):
                    step_pos = int(round(i * step_interval))
                    if step_pos < length:
                        sequence[step_pos] = 0x04
                return sequence


class TopologyAnalyzer:
    """Analyzes GyroSI topology evolution and physics patterns."""
    
    def __init__(self, atlas_paths: AtlasPaths):
        """
        Initialize with atlas maps.
        
        Args:
            atlas_paths: Paths to the five canonical maps
        """
        self.atlas_paths = atlas_paths
        self.mapper = FermionToIntronMapper()
        
        # Load atlas maps
        self._load_atlas_maps()
        
        # Initialize archetype state
        self.archetype_state = governance.tensor_to_int(governance.GENE_Mac_S)
        
        # Prepare layer patterns for signature computation
        self._prepare_layer_patterns()
        
    def _load_atlas_maps(self) -> None:
        """Load the five canonical atlas maps."""
        try:
            
            self.ontology_keys = np.load(self.atlas_paths.ontology, mmap_mode='r')
            self.epistemology = np.load(self.atlas_paths.epistemology, mmap_mode='r') 
            self.phenomenology_map = np.load(self.atlas_paths.phenomenology, mmap_mode='r')
            self.theta = np.load(self.atlas_paths.theta, mmap_mode='r')
            self.orbit_sizes = np.load(self.atlas_paths.orbit_sizes, mmap_mode='r')
            

        except FileNotFoundError as e:
            logger.error(f"Atlas maps not found: {e}")
            logger.error("Run with --build-atlas first to generate maps")
            raise
    
    def _prepare_layer_patterns(self) -> None:
        """Prepare layer patterns for signature computation."""
        # Extract 4-layer patterns from GENE_Mac_S
        self.layer_patterns = []
        for i in range(4):
            layer = governance.GENE_Mac_S[i].astype(np.int8).flatten()
            # Map +1→0, -1→1 to match 48-bit packing
            pattern = np.where(layer > 0, 0, 1).astype(np.uint8)
            # Ensure pattern is 48 bits long
            if len(pattern) != 48:
                # Pad or truncate to 48 bits
                if len(pattern) < 48:
                    pattern = np.pad(pattern, (0, 48 - len(pattern)), 'constant')
                else:
                    pattern = pattern[:48]
            self.layer_patterns.append(pattern)
    
    def state_to_bits(self, state: int) -> np.ndarray[np.uint8, np.dtype[np.uint8]]:
        """Convert 48-bit state to bit vector."""
        # 48-bit little-endian bool vector (0/1)
        bits = np.unpackbits(np.array([state >> 16, state & 0xFFFF], dtype='>u8').view(np.uint8))[-48:]
        return bits.astype(np.uint8)
    
    def layer_signature(self, state: int) -> Dict[str, Any]:
        """Compute layer signature for a state using tensor correlation."""
        T = governance.int_to_tensor(state).astype(np.int8)  # shape [4,2,3,2], ±1
        scores = [int(np.sum(T[i] * governance.GENE_Mac_S[i])) for i in range(4)]
        dominant = int(np.argmax(scores))
        return {'scores': scores, 'dominant': dominant}
    
    def _check_720_closure(self, layer_sequence: List[int]) -> bool:
        """
        Check if layer sequence completes a 720° spinor cycle.
        
        A 720° cycle requires progression through all 4 layers in sequence.
        This can be 0→1→2→3→0 or any rotation-equivalent.
        """
        if len(layer_sequence) < 4:
            return False
        
        # Check if all 4 layers are represented
        unique_layers = set(layer_sequence)
        if len(unique_layers) != 4:
            return False
        
        # Check for sequential progression (allowing for rotation)
        # Look for any 4-step subsequence that cycles through all layers
        for i in range(len(layer_sequence) - 3):
            subseq = layer_sequence[i:i+4]
            if len(set(subseq)) == 4:  # All 4 layers in 4 steps
                return True
        
        return False
    
    def apply_intron_to_state(self, state: int, intron: int) -> int:
        """
        Apply intron using atlas-only dynamics.
        
        Enforces that all state transitions must go through the measured atlas.
        This ensures we're using the actual physics of the 788,986-state manifold.
        
        Args:
            state: Current state integer
            intron: 8-bit intron to apply
            
        Returns:
            Next state integer
            
        Raises:
            ValueError: If state not found in ontology (indicates mapping bug)
        """
        state_idx = np.searchsorted(self.ontology_keys, state)
        if state_idx >= len(self.ontology_keys) or self.ontology_keys[state_idx] != state:
            raise ValueError(f"State 0x{state:012x} not in ontology; illegal path or mapping bug")
        next_state_idx = self.epistemology[state_idx, intron]
        return int(self.ontology_keys[next_state_idx])
    
    def fold(self, a: int, b: int) -> int:
        """Monodromic fold: a ⋄ b = a ⊕ (b ⊕ (a ∧ ¬b))"""
        return a ^ (b ^ (a & (~b & 0xFF)))
    
    def evolve_path(self, start_state: int, introns: List[int]) -> Tuple[List[int], int]:
        """
        Evolve path using atlas-only transitions and Monodromic Fold.
        
        Args:
            start_state: Starting state
            introns: Sequence of introns to apply
            
        Returns:
            Tuple of (state_path, final_monodromy)
        """
        state = start_state
        monodromy = 0
        path = [state]
        
        for intron in introns:
            state = self.apply_intron_to_state(state, intron)  # atlas-only
            monodromy = self.fold(monodromy, intron)           # path memory
            path.append(state)
        
        return path, monodromy
    
    def get_state_metrics(self, state: int, anchor: int) -> Dict[str, Any]:
        """
        Get comprehensive metrics for a state.
        
        Args:
            state: State integer
            anchor: Anchor state for coordinate computation
            
        Returns:
            Dictionary of state metrics
        """
        # Find state index
        state_idx = np.searchsorted(self.ontology_keys, state)
        
        if (state_idx >= len(self.ontology_keys) or 
            self.ontology_keys[state_idx] != state):
            # State not in ontology - compute directly
            theta_val = math.acos(1 - 2 * (state ^ anchor).bit_count() / 48.0)
            orbit_size = 1  # Unknown
            orbit_rep = state
        else:
            # Use atlas data
            theta_val = float(self.theta[state_idx])
            orbit_size = int(self.orbit_sizes[state_idx])
            orbit_rep = int(self.phenomenology_map[state_idx])
        
        return {
            'state': state,
            'state_hex': f"0x{state:012x}",
            'theta': theta_val,
            'orbit_size': orbit_size,
            'orbit_rep': orbit_rep,
            'hamming_from_anchor': (state ^ anchor).bit_count()
        }
    
    def run_experiment(self, fermion_data: FermionData, config: ExperimentConfig) -> List[TopologyExperiment]:
        """
        Run complete topology experiment for fermion sector.
        
        Args:
            fermion_data: Fermion observables
            config: Experiment configuration
            
        Returns:
            List of experiment results
        """        
        # Set random seed for reproducibility
        np.random.seed(config.random_seed)
        random.seed(config.random_seed)
        
        experiments = []
        
        for trial in range(config.num_trials):
            for perturbation in range(config.num_perturbations):
                experiment = TopologyExperiment(
                    sector=fermion_data.sector,
                    trial_id=trial * config.num_perturbations + perturbation,
                    fermion_data=fermion_data,
                    config=config
                )
                
                # Generate intron sequence
                pert_seed = config.random_seed + trial * 100 + perturbation
                experiment.intron_sequence = self.mapper.generate_intron_sequence(
                    fermion_data, config.num_steps, pert_seed
                )
                
                # Run state evolution
                self._evolve_experiment(experiment)
                
                # Compute metrics
                self._analyze_experiment(experiment)
                
                experiments.append(experiment)
        
        return experiments
    
    def _evolve_experiment(self, experiment: TopologyExperiment) -> None:
        """Evolve experiment using proper path evolution with Monodromic Fold."""
        anchor = self.archetype_state
        
        # Evolve step by step to track monodromy at each step
        state = self.archetype_state
        monodromy = 0
        
        # Build experiment path with metrics
        for step in range(len(experiment.intron_sequence) + 1):
            if step == 0:
                # Initial state
                experiment.path.append({
                    'step': 0,
                    'intron': None,
                    'monodromy': 0,
                    **self.get_state_metrics(state, anchor)
                })
            else:
                # Apply intron and update monodromy
                intron = experiment.intron_sequence[step - 1]
                if intron is None:
                    # True no-op - same state, no monodromy update
                    experiment.path.append({
                        'step': step,
                        'intron': None,
                        'monodromy': monodromy,
                        **self.get_state_metrics(state, anchor)
                    })
                else:
                    # Real intron - apply and update monodromy
                    state = self.apply_intron_to_state(state, intron)  # atlas-only
                    monodromy = self.fold(monodromy, intron)           # path memory
                    
                    experiment.path.append({
                        'step': step,
                        'intron': intron,
                        'intron_hex': f"0x{intron:02x}",
                        'monodromy': monodromy,
                        **self.get_state_metrics(state, anchor)
                    })
    
    def _analyze_experiment(self, experiment: TopologyExperiment) -> None:
        """Analyze experiment for physics patterns."""
        path = experiment.path
        
        if len(path) < 2:
            return
        
        # Track layer progression and structural changes
        layer_transitions = 0
        parity_flips = 0
        orbit_changes = 0
        theta_progression = []
        layer_sequence = []

        for i in range(len(path)):
            state = path[i]['state']
            
            # Get layer signature for this state
            signature = self.layer_signature(state)
            layer_sequence.append(signature['dominant'])
            
            # Count layer transitions (structural changes)
            # Use layer signature scores to detect significant changes
            if i > 0:
                prev_sig = self.layer_signature(path[i-1]['state'])
                curr_sig = self.layer_signature(state)
                
                # Check if layer pattern changed significantly
                prev_scores = prev_sig['scores']
                curr_scores = curr_sig['scores']
                
                # Count layers that changed sign or had significant score changes
                significant_changes = 0
                for j in range(4):
                    prev_score = prev_scores[j]
                    curr_score = curr_scores[j]
                    
                    # Significant change: sign flip or large magnitude change
                    if (prev_score * curr_score < 0) or (abs(prev_score - curr_score) > 10):
                        significant_changes += 1
                
                if significant_changes > 0:
                    layer_transitions += 1

            # Parity flips: count LI events from intron bits (when LI is enabled)
            # For aperture-only experiment (LI disabled), this should be identically zero
            # Since LI is disabled in this experiment, parity flips should be identically zero
            # This is correct and helpful for aperture-only tests
                
            if i > 0 and path[i-1]['orbit_rep'] != path[i]['orbit_rep']:
                orbit_changes += 1
                
            theta_progression.append(path[i]['theta'])
        
        # Helical closure analysis (720° spinor logic)
        final_theta = path[-1]['theta']
        
        # 720° Spinor Closure Analysis using layer signatures
        # Check if layer sequence completes a 4-layer cycle (0→1→2→3→0 or equivalent)
        closure_720 = self._check_720_closure(layer_sequence)
        
        # Use 720° closure as the main metric (no near-closure due to 2-layer degeneracy)
        closure_achieved = closure_720
        
        # 30-fold analysis (proper phase modulo)
        total_phase = sum(abs(path[i]['theta'] - path[i-1]['theta']) 
                         for i in range(1, len(path)))
        # Convert to 30-fold phase and compute alignment
        phase_30 = total_phase * 30 / math.pi
        phase_frac = phase_30 % 1.0
        fold_30_alignment = 1.0 - min(phase_frac, 1.0 - phase_frac) * 2.0
        
        # Signed net phase analysis (complementary lens)
        net_phase = sum(path[i]['theta'] - path[i-1]['theta'] 
                       for i in range(1, len(path)))
        net_phase_30 = net_phase * 30 / math.pi
        net_phase_frac = net_phase_30 % 1.0
        net_fold_30_alignment = 1.0 - min(net_phase_frac, 1.0 - net_phase_frac) * 2.0  # Distance to nearest integer
        
        # Aperture quantization analysis
        aperture_steps = []
        clicks_per_step = []
        for i in range(1, len(path)):
            hamming_change = abs(path[i]['hamming_from_anchor'] - 
                               path[i-1]['hamming_from_anchor'])
            aperture_steps.append(hamming_change)
            
            # Compute actual 3° clicks per step
            theta_change = abs(path[i]['theta'] - path[i-1]['theta'])
            clicks = theta_change / (math.pi / 60)  # π/60 = 3°
            clicks_per_step.append(clicks)
        
        # Report true clicks per micro-step from calibration
        real_introns = [p['intron'] for p in path if p['intron'] is not None and p['intron'] != 0x00]
        microsteps_applied = len(real_introns)
        clicks_per_microstep = 10.302  # From FG1 calibration
        total_clicks_target = abs(experiment.fermion_data.clicks_e21)
        total_clicks_realized = sum(clicks_per_step)  # Sum of actual theta changes
        
        # Orbit stability
        orbit_stability = 1.0 - (orbit_changes / max(1, len(path) - 1))
        
        # CGM stage correlation
        cgm_correlation = self._compute_cgm_correlation(experiment)
        
        # Track layer progression through 4-layer structure (unused for now)
        # layer_progression = self._track_layer_progression(path)
        
        # Track monodromy accumulation
        final_monodromy = path[-1]['monodromy'] if 'monodromy' in path[-1] else 0
        
        # Sanity check: monodromy should accumulate with real intron operations
        real_introns = [p['intron'] for p in path if p['intron'] is not None and p['intron'] != 0x00]
        if real_introns:
            # Check that monodromy actually changes with real operations
            monodromy_values = [p['monodromy'] for p in path if p['intron'] is not None and p['intron'] != 0x00]
            if len(monodromy_values) > 1:
                monodromy_changes = [abs(monodromy_values[i] - monodromy_values[i-1]) for i in range(1, len(monodromy_values))]
                avg_monodromy_change = np.mean(monodromy_changes) if monodromy_changes else 0
                if avg_monodromy_change == 0:
                    print(f"WARNING: Monodromy not accumulating with real intron operations in {experiment.sector} sector")
        
        experiment.metrics = {
            'layer_transitions': layer_transitions,  # Structural changes via layer progression
            'parity_flips': parity_flips,
            'orbit_changes': orbit_changes,
            'final_theta': final_theta,
            'closure_achieved': closure_achieved,
            'closure_720': closure_720,  # 720° spinor closure
            'total_phase': total_phase,
            'fold_30_alignment': fold_30_alignment,
            'net_phase': net_phase,
            'net_fold_30_alignment': net_fold_30_alignment,
            'layer_sequence': layer_sequence,  # 4-layer helical progression
            'final_monodromy': final_monodromy,  # Monodromic fold accumulation
            'aperture_steps': aperture_steps,
            'avg_hamming_step': np.mean(aperture_steps) if aperture_steps else 0,
            'clicks_per_step': clicks_per_step,
            'avg_clicks_per_step': np.mean(clicks_per_step) if clicks_per_step else 0,
            'microsteps_applied': microsteps_applied,
            'clicks_per_microstep': clicks_per_microstep,
            'total_clicks_target': total_clicks_target,
            'total_clicks_realized': total_clicks_realized,
            'orbit_stability': orbit_stability,
            'cgm_correlation': cgm_correlation,
            'theta_progression': theta_progression,
            'path_length': len(path) - 1
        }
    
    def _compute_cgm_correlation(self, experiment: TopologyExperiment) -> Dict[str, float]:
        """Compute correlation with CGM stage progression."""
        path = experiment.path
        
        if len(path) < 5:  # Need at least 4 stages
            return {'cs': 0, 'una': 0, 'ona': 0, 'bu': 0}
        
        # CGM stage angles: π/2, π/4, π/4, 0
        cgm_angles = [math.pi/2, math.pi/4, math.pi/4, 0]
        cgm_stages = ['cs', 'una', 'ona', 'bu']
        
        correlations = {}
        
        for i, (stage, expected_theta) in enumerate(zip(cgm_stages, cgm_angles)):
            if i + 1 < len(path):
                actual_theta = path[i + 1]['theta']
                # Correlation as inverse of angular difference
                diff = abs(actual_theta - expected_theta)
                correlation = max(0, 1 - diff / math.pi)
                correlations[stage] = correlation
            else:
                correlations[stage] = 0
        
        return correlations
    
    def _track_layer_progression(self, path: List[Dict[str, Any]]) -> List[int]:
        """
        Track progression through the 4-layer structure of GENE_Mac_S.
        
        Returns list of dominant layer indices (0-3) for each step.
        """
        layer_progression = []
        
        for point in path:
            state = point['state']
            tensor = governance.int_to_tensor(state)
            
            # Find which layer has the strongest alignment
            layer_alignments = []
            for layer in range(4):
                # Compare with GENE_Mac_S layer
                layer_diff = np.sum(np.abs(tensor[layer] - governance.GENE_Mac_S[layer]))
                layer_alignments.append(layer_diff)
            
            # Find layer with minimum difference (best alignment)
            dominant_layer = int(np.argmin(layer_alignments))
            layer_progression.append(dominant_layer)
        
        return layer_progression
    
    def _classify_plane_li_invariant(self, state: int) -> str:
        """
        Classify plane based on even vs odd layer dominance (FG/BG structure).
        
        FG toggles layers 0 and 2 (even); BG toggles 1 and 3 (odd).
        This classification is sensitive to FG/BG changes while remaining LI-invariant.
        
        Args:
            state: State integer
            
        Returns:
            Plane classification: 'CS/UNA' or 'ONA/BU'
        """
        # Convert state to tensor to analyze layer structure
        tensor = governance.int_to_tensor(state)
        
        # Analyze even vs odd layer dominance
        # CORRECTED: FG affects layers 1,3; BG affects layers 0,2
        even_layers = tensor[[1, 3], :, :, :]  # Layers 1 and 3 (FG-affected)
        odd_layers = tensor[[0, 2], :, :, :]   # Layers 0 and 2 (BG-affected)
        
        # Count +1 vs -1 in each layer group
        even_plus = np.sum(even_layers == 1)
        even_minus = np.sum(even_layers == -1)
        odd_plus = np.sum(odd_layers == 1)
        odd_minus = np.sum(odd_layers == -1)
        
        # CS/UNA: even layers dominant in +1, odd layers dominant in -1
        # ONA/BU: odd layers dominant in +1, even layers dominant in -1
        even_dominance = even_plus - even_minus
        odd_dominance = odd_plus - odd_minus
        
        if even_dominance > odd_dominance:
            return "CS/UNA"
        else:
            return "ONA/BU"
    
    def compute_correlation_check(self, experiments: List[TopologyExperiment]) -> Dict[str, float]:
        """Compute correlation between clicks_e21 and plane_flips."""
        if not experiments:
            return {}
        
        clicks_e21_values = [exp.fermion_data.clicks_e21 for exp in experiments]
        plane_flips_values = [exp.metrics['plane_flips'] for exp in experiments]
        
        if len(clicks_e21_values) < 2:
            return {'correlation': 0.0, 'r_squared': 0.0}
        
        # Compute Pearson correlation
        correlation = float(np.corrcoef(clicks_e21_values, plane_flips_values)[0, 1])
        r_squared = correlation ** 2
        
        return {
            'correlation': correlation,
            'r_squared': r_squared
        }


class TopologyReporter:
    """Generate comprehensive analysis reports."""
    
    def __init__(self):
        """Initialize reporter."""
        pass
    
    def _compute_correlation_check(self, experiments: List[TopologyExperiment]) -> Dict[str, float]:
        """Compute correlation between clicks_e21 and plane_flips for validation."""
        if not experiments:
            return {}
        
        clicks_e21_values = [exp.fermion_data.clicks_e21 for exp in experiments]
        plane_flips_values = [exp.metrics['plane_flips'] for exp in experiments]
        
        if len(clicks_e21_values) < 2:
            return {'correlation': 0.0, 'r_squared': 0.0}
        
        # Check if all clicks_e21 values are the same (within-sector correlation)
        if len(set(clicks_e21_values)) == 1:
            return {'correlation': float('nan'), 'r_squared': float('nan')}
        
        # Compute Pearson correlation
        try:
            correlation = float(np.corrcoef(clicks_e21_values, plane_flips_values)[0, 1])
            r_squared = correlation ** 2
        except (ValueError, RuntimeWarning):
            return {'correlation': float('nan'), 'r_squared': float('nan')}
        
        return {
            'correlation': correlation,
            'r_squared': r_squared
        }
    
    def compute_cross_sector_correlation(self, all_results: Dict[str, Any]) -> Dict[str, float]:
        """Compute correlation between clicks_e21 and plane_flips across sectors."""
        if len(all_results) < 2:
            return {'correlation': 0.0, 'r_squared': 0.0}
        
        # Collect sector-level data
        sector_data = []
        for sector, data in all_results.items():
            fermion = data['fermion_data']
            metrics = data['metrics']
            sector_data.append({
                'sector': sector,
                'clicks_e21': fermion.clicks_e21,
                'avg_layer_transitions': metrics['avg_layer_transitions']
            })
        
        clicks_values = [d['clicks_e21'] for d in sector_data]
        layer_transitions_values = [d['avg_layer_transitions'] for d in sector_data]
        
        try:
            correlation = float(np.corrcoef(clicks_values, layer_transitions_values)[0, 1])
            r_squared = correlation ** 2
        except (ValueError, RuntimeWarning):
            return {'correlation': float('nan'), 'r_squared': float('nan')}
        
        return {
            'correlation': correlation,
            'r_squared': r_squared
        }
    
    def generate_sector_report(
        self, 
        sector: str, 
        experiments: List[TopologyExperiment],
        fermion_data: FermionData
    ) -> str:
        """Generate detailed sector analysis report."""
        report = []
        
        report.append(f"\n{'='*8}")
        report.append(f"TOPOLOGY ANALYSIS REPORT: {sector.upper()} SECTOR")
        report.append(f"{'='*8}")
        
        # Fermion data summary
        report.append(f"\nFermion Observables:")
        report.append(f"  e21 = {fermion_data.e21:.6f} (primary diagnostic)")
        report.append(f"  e32 = {fermion_data.e32:.6f}")
        report.append(f"  3° clicks: e21={fermion_data.clicks_e21:.2f}, e32={fermion_data.clicks_e32:.2f}")
        report.append(f"  30-fold residual = {fermion_data.residual:.6f}")
        report.append(f"  Mass ratio impact = {fermion_data.aperture_impact:.3f}")
        
        # Aggregate metrics
        metrics = self._aggregate_metrics(experiments)
        
        report.append(f"\nTopology Experiment Results (n={len(experiments)}):")
        report.append(f"  Avg layer transitions: {metrics['avg_layer_transitions']:.2f} (4-layer progression)")
        report.append(f"  Avg parity flips: {metrics['avg_parity_flips']:.2f} (LI mirror parity)")
        report.append(f"  720° closure: {metrics['closure_720_rate']*100:.1f}% (spinor return)")
        report.append(f"  Avg final theta: {metrics['avg_final_theta']:.3f} rad (BU alignment)")
        report.append(f"  30-fold alignment: {metrics['avg_30fold_alignment']:.3f} (phase division)")
        report.append(f"  Final monodromy: {metrics['avg_final_monodromy']:.2f} (fold accumulation)")
        report.append(f"  Orbit stability: {metrics['avg_orbit_stability']*100:.1f}% (particle-like)")
        report.append(f"  Avg Hamming step to anchor: {metrics['avg_hamming_step']:.2f} bits")
        report.append(f"  Avg clicks per step: {metrics['avg_clicks_per_step']:.2f} (3° aperture)")
        report.append(f"  Microsteps applied: {metrics['microsteps_applied']} (real introns)")
        report.append(f"  Clicks per microstep: {metrics['clicks_per_microstep']:.2f} (calibrated)")
        report.append(f"  Total clicks: {metrics['total_clicks_target']:.2f} target → {metrics['total_clicks_realized']:.2f} realized")
        
        # CGM stage correlations
        cgm_corr = metrics['avg_cgm_correlation']
        report.append(f"\nCGM Stage Correlations:")
        report.append(f"  CS (π/2): {cgm_corr['cs']:.3f}")
        report.append(f"  UNA (π/4): {cgm_corr['una']:.3f}")
        report.append(f"  ONA (π/4): {cgm_corr['ona']:.3f}")
        report.append(f"  BU (0): {cgm_corr['bu']:.3f}")
        
        # Note: Within-sector correlation not meaningful since all experiments have same clicks_e21
        # Cross-sector correlation is shown in comparative report
        
        # Physics interpretation
        report.append(f"\nPhysics Interpretation:")
        
        if fermion_data.clicks_e21 < 0.2:
            report.append(f"  • Near-orthogonal sector (clean 45° backbone)")
            report.append(f"  • Minimal aperture perturbations")
            report.append(f"  • Expected: Low plane flips, high closure rate")
        elif fermion_data.clicks_e21 > 2.0:
            report.append(f"  • High-aperture sector (~{fermion_data.clicks_e21:.1f} clicks)")
            report.append(f"  • Strong 3° quantization effects")
            report.append(f"  • Expected: More plane flips, complex oscillations")
        else:
            report.append(f"  • Moderate aperture sector (~{fermion_data.clicks_e21:.1f} clicks)")
            report.append(f"  • Intermediate dynamics")
        
        if metrics['closure_720_rate'] > 0.8:
            report.append(f"  • Strong 720° closure → stable particle-like behavior")
        elif metrics['closure_720_rate'] > 0.5:
            report.append(f"  • Near closure → oscillatory behavior")
        else:
            report.append(f"  • Weak closure → chaotic/dissipative dynamics")
        
        if metrics['avg_30fold_alignment'] > 0.8:
            report.append(f"  • Excellent 30-fold alignment → clean phase structure")
        elif metrics['avg_30fold_alignment'] > 0.5:
            report.append(f"  • Good 30-fold alignment → structured with noise")
        else:
            report.append(f"  • Poor 30-fold alignment → disordered phase")
        
        # Sample path analysis
        if experiments:
            report.append(f"\nSample Path Analysis (Trial 0):")
            sample_path = experiments[0].path[:4]  # First 4 steps
            for point in sample_path:
                # Simplified plane display (CS/UNA for archetype, ONA/BU for evolved states)
                plane = "CS/UNA" if point['step'] == 0 else "ONA/BU"
                if point['step'] == 0:
                    report.append(f"  Step {point['step']}: {plane} "
                                f"(θ={point['theta']:.3f}, orbit_size={point['orbit_size']})")
                else:
                    report.append(f"  Step {point['step']}: {plane} "
                                f"(θ={point['theta']:.3f}, intron={point['intron_hex']})")
        
        return '\n'.join(report)
    
    def _aggregate_metrics(self, experiments: List[TopologyExperiment]) -> Dict[str, Any]:
        """Aggregate metrics across experiments."""
        if not experiments:
            return {}
        
        # Collect all metrics
        all_metrics = [exp.metrics for exp in experiments]
        
        # Compute averages
        avg_metrics: Dict[str, Any] = {
            'avg_layer_transitions': float(np.mean([m['layer_transitions'] for m in all_metrics])),
            'avg_parity_flips': float(np.mean([m['parity_flips'] for m in all_metrics])),
            'avg_final_theta': float(np.mean([m['final_theta'] for m in all_metrics])),
            'closure_720_rate': float(np.mean([m['closure_720'] for m in all_metrics])),
            'avg_30fold_alignment': float(np.mean([m['fold_30_alignment'] for m in all_metrics])),
            'avg_final_monodromy': float(np.mean([m['final_monodromy'] for m in all_metrics])),
            'avg_orbit_stability': float(np.mean([m['orbit_stability'] for m in all_metrics])),
            'avg_hamming_step': float(np.mean([m['avg_hamming_step'] for m in all_metrics])),
            'avg_clicks_per_step': float(np.mean([m['avg_clicks_per_step'] for m in all_metrics])),
        }
        
        # CGM correlations
        cgm_keys = ['cs', 'una', 'ona', 'bu']
        avg_cgm = {}
        for key in cgm_keys:
            values = [m['cgm_correlation'][key] for m in all_metrics if key in m['cgm_correlation']]
            avg_cgm[key] = float(np.mean(values)) if values else 0.0
        
        # Store as regular dict, not numpy array
        avg_metrics['avg_cgm_correlation'] = dict(avg_cgm)
        
        return avg_metrics
    
    def generate_comparative_report(self, all_results: Dict[str, Any]) -> str:
        """Generate comparative analysis across sectors."""
        report = []
        
        report.append(f"\n{'='*8}")
        report.append(f"COMPARATIVE TOPOLOGY ANALYSIS")
        report.append(f"{'='*8}")
        
        # Extract sector data
        sectors = list(all_results.keys())
        
        report.append(f"\nSector Comparison:")
        report.append(f"{'Sector':<10} {'Clicks':<8} {'720°%':<6} {'Near%':<6} {'30fold':<8} {'Layers':<8} {'CGM-BU':<8}")
        report.append(f"{'-'*60}")
        
        for sector in sectors:
            data = all_results[sector]
            fermion = data['fermion_data']
            metrics = data['metrics']
            
            report.append(f"{sector:<10} {fermion.clicks_e21:<8.2f} "
                         f"{metrics['closure_720_rate']*100:<6.1f} "
                         f"{metrics['closure_720_rate']*100:<6.1f} "
                         f"{metrics['avg_30fold_alignment']:<8.3f} "
                         f"{metrics['avg_layer_transitions']:<8.2f} "
                         f"{metrics['avg_cgm_correlation']['bu']:<8.3f}")
        
        # Physics insights
        report.append(f"\nCross-Sector Physics Insights:")
        
        # Find cleanest sector
        cleanest_sector = min(sectors, 
                            key=lambda s: all_results[s]['fermion_data'].residual)
        report.append(f"  • Cleanest 30-fold: {cleanest_sector} sector "
                     f"(residual = {all_results[cleanest_sector]['fermion_data'].residual:.3f})")
        
        # Find most stable closure (720°)
        closure_720_rates = [all_results[s]['metrics']['closure_720_rate'] for s in sectors]
        if all(rate == 0.0 for rate in closure_720_rates):
            report.append(f"  • Highest 720° closure: none (all sectors at 0.0%)")
        else:
            most_stable = max(sectors,
                             key=lambda s: all_results[s]['metrics']['closure_720_rate'])
            report.append(f"  • Highest 720° closure: {most_stable} sector "
                         f"({all_results[most_stable]['metrics']['closure_720_rate']*100:.1f}%)")
        
        
        # Aperture click correlation
        click_data = [(s, all_results[s]['fermion_data'].clicks_e21, 
                      all_results[s]['metrics']['avg_layer_transitions']) for s in sectors]
        click_data.sort(key=lambda x: x[1])  # Sort by clicks
        
        report.append(f"  • Aperture click hierarchy:")
        for sector, clicks, transitions in click_data:
            report.append(f"    {sector}: {clicks:.2f} clicks → {transitions:.2f} avg layer transitions")
        
        # CGM stage progression
        report.append(f"  • CGM stage progression patterns:")
        for sector in sectors:
            cgm = all_results[sector]['metrics']['avg_cgm_correlation']
            strongest_stage = max(cgm.keys(), key=lambda k: cgm[k])
            report.append(f"    {sector}: strongest at {strongest_stage.upper()} "
                         f"(correlation = {cgm[strongest_stage]:.3f})")
        
        # Cross-sector correlation
        cross_corr = self.compute_cross_sector_correlation(all_results)
        if not np.isnan(cross_corr['correlation']):
            report.append(f"\nCross-Sector Correlation:")
            report.append(f"  clicks_e21 vs avg_layer_transitions correlation: {cross_corr['correlation']:.3f}")
            report.append(f"  R²: {cross_corr['r_squared']:.3f}")
        else:
            report.append(f"\nCross-Sector Correlation:")
            report.append(f"  Correlation computation failed or insufficient data")
        
        return '\n'.join(report)


def create_fermion_data() -> Dict[str, FermionData]:
    """Create fermion data from CGM analysis results."""
    return {
        'up': FermionData(
            sector='up',
            e32=-1.679218,
            e21=-2.236067,
            e13=3.915285,
            clicks_e32=4.25,
            clicks_e21=0.84,
            residual=0.458539,
            mass_ratio=577.3,
            aperture_impact=1.027
        ),
        'down': FermionData(
            sector='down',
            e32=-1.132623,
            e21=-0.501723,
            e13=1.634347,
            clicks_e32=7.04,
            clicks_e21=-0.10,
            residual=0.030396,
            mass_ratio=20.0,
            aperture_impact=0.997
        ),
        'lepton': FermionData(
            sector='lepton',
            e32=-0.657414,
            e21=-1.706509,
            e13=2.363923,
            clicks_e32=5.56,
            clicks_e21=2.61,
            residual=0.082307,
            mass_ratio=206.8,
            aperture_impact=1.088
        )
    }


# Validation suite removed - not needed for core physics analysis

def main():
    """Main entry point for topology analysis."""
    parser = argparse.ArgumentParser(
        description="GyroSI Topology Analysis: Fermion Mass Patterns in Recursive Structural Intelligence",
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    
    parser.add_argument('--experiment', choices=['all', 'up', 'down', 'lepton'],
                       help='Run topology experiments')
    parser.add_argument('--num-trials', type=int, default=10,
                       help='Number of trials per experiment')
    parser.add_argument('--num-steps', type=int, default=6,
                       help='Path length (system diameter)')
    parser.add_argument('--seed', type=int, default=42,
                       help='Random seed for reproducibility')
    
    args = parser.parse_args()
    
    if not args.experiment:
        parser.print_help()
        return
    
    # Setup configuration
    config = ExperimentConfig(
        num_steps=args.num_steps,
        num_trials=args.num_trials,
        random_seed=args.seed
    )
    
    # Initialize analyzer with pre-built atlas maps
    atlas_paths = AtlasPaths.from_directory(Path("memories/public/meta"))
    analyzer = TopologyAnalyzer(atlas_paths)
    reporter = TopologyReporter()
    
    # Run experiments if requested
    if args.experiment:
        fermion_data = create_fermion_data()
        all_results = {}
        
        sectors = [args.experiment] if args.experiment != 'all' else ['up', 'down', 'lepton']
        
        for sector in sectors:
            experiments = analyzer.run_experiment(fermion_data[sector], config)
            metrics = reporter._aggregate_metrics(experiments)
            
            all_results[sector] = {
                'experiments': experiments,
                'fermion_data': fermion_data[sector],
                'metrics': metrics
            }
            
            # Generate sector report
            sector_report = reporter.generate_sector_report(
                sector, experiments, fermion_data[sector]
            )
            print(sector_report)
        
        # Generate comparative report if multiple sectors
        if len(all_results) > 1:
            comparative_report = reporter.generate_comparative_report(all_results)
            print(comparative_report)
        
        # Summary
        print(f"\n{'='*8}")
        print("TOPOLOGY ANALYSIS COMPLETE")
        print(f"{'='*8}")
        print(f"Total experiments: {sum(len(r['experiments']) for r in all_results.values())}")


if __name__ == "__main__":
    main()